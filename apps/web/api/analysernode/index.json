{"doc":{"isMarkdown":true,"isTranslated":false,"isActive":true,"flaws":{},"title":"AnalyserNode","mdn_url":"/en-US/docs/Web/API/AnalyserNode","locale":"en-US","native":"English (US)","browserCompat":["api.AnalyserNode"],"baseline":{"baseline":"high","baseline_high_date":"2023-10-26","baseline_low_date":"2021-04-26","support":{"chrome":"35","chrome_android":"35","edge":"12","firefox":"25","firefox_android":"25","safari":"14.1","safari_ios":"14.5"}},"sidebarHTML":"<ol><li class=\"section\"><a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a></li><li class=\"section\"><em><a href=\"/en-US/docs/Web/API/AnalyserNode\" aria-current=\"page\"><code>AnalyserNode</code></a></em></li><li class=\"toggle\"><details open=\"\"><summary>Constructor</summary><ol><li><a href=\"/en-US/docs/Web/API/AnalyserNode/AnalyserNode\"><code>AnalyserNode()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Instance properties</summary><ol><li><a href=\"/en-US/docs/Web/API/AnalyserNode/fftSize\"><code>fftSize</code></a></li><li><a href=\"/en-US/docs/Web/API/AnalyserNode/frequencyBinCount\"><code>frequencyBinCount</code></a></li><li><a href=\"/en-US/docs/Web/API/AnalyserNode/maxDecibels\"><code>maxDecibels</code></a></li><li><a href=\"/en-US/docs/Web/API/AnalyserNode/minDecibels\"><code>minDecibels</code></a></li><li><a href=\"/en-US/docs/Web/API/AnalyserNode/smoothingTimeConstant\"><code>smoothingTimeConstant</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Instance methods</summary><ol><li><a href=\"/en-US/docs/Web/API/AnalyserNode/getByteFrequencyData\"><code>getByteFrequencyData()</code></a></li><li><a href=\"/en-US/docs/Web/API/AnalyserNode/getByteTimeDomainData\"><code>getByteTimeDomainData()</code></a></li><li><a href=\"/en-US/docs/Web/API/AnalyserNode/getFloatFrequencyData\"><code>getFloatFrequencyData()</code></a></li><li><a href=\"/en-US/docs/Web/API/AnalyserNode/getFloatTimeDomainData\"><code>getFloatTimeDomainData()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Inheritance</summary><ol><li><a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li><li><a href=\"/en-US/docs/Web/API/EventTarget\"><code>EventTarget</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Related pages for Web Audio API</summary><ol><li><a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioListener\"><code>AudioListener</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioParam\"><code>AudioParam</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a><abbr class=\"icon icon-deprecated\" title=\"Deprecated. Not for use in new websites.\">\n  <span class=\"visually-hidden\">Deprecated</span>\n</abbr></li><li><a href=\"/en-US/docs/Web/API/AudioScheduledSourceNode\"><code>AudioScheduledSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioSinkInfo\"><code>AudioSinkInfo</code></a><abbr class=\"icon icon-experimental\" title=\"Experimental. Expect behavior to change in the future.\">\n    <span class=\"visually-hidden\">Experimental</span>\n</abbr></li><li><a href=\"/en-US/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope\"><code>AudioWorkletGlobalScope</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConstantSourceNode\"><code>ConstantSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/GainNode\"><code>GainNode</code></a></li><li><a href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></li><li><a href=\"/en-US/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code></a></li></ol></details></li></ol>","sidebarMacro":"APIRef","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>The <strong><code>AnalyserNode</code></strong> interface represents a node able to provide real-time frequency and time-domain analysis information. It is an <a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a> that passes the audio stream unchanged from the input to the output, but allows you to take the generated data, process it, and create audio visualizations.</p>\n<p>An <code>AnalyserNode</code> has exactly one input and one output. The node works even if the output is not connected.</p>\n<p>\n  <img src=\"/en-US/docs/Web/API/AnalyserNode/fttaudiodata_en.svg\" alt=\"Without modifying the audio stream, the node allows to get the frequency and time-domain data associated to it, using a FFT.\" width=\"693\" height=\"206\" loading=\"lazy\">\n</p><svg viewBox=\"-1 -1 650 42\" preserveAspectRatio=\"xMinYMin meet\">\n  <a style=\"text-decoration: none;\" href=\"/en-US/docs/Web/API/EventTarget\">\n    <rect x=\"0\" y=\"0\" width=\"88\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"44\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      EventTarget\n    </text>\n  </a>\n  <line x1=\"88\" y1=\"14\" x2=\"118\" y2=\"14\" stroke=\"#D4DDE4\"></line>\n  <polyline points=\"88,14 98,9 98,19 88,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" href=\"/en-US/docs/Web/API/AudioNode\">\n    <rect x=\"118\" y=\"0\" width=\"75\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"155.5\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      AudioNode\n    </text>\n  </a>\n  <line x1=\"193\" y1=\"14\" x2=\"223\" y2=\"14\" stroke=\"#D4DDE4\"></line>\n  <polyline points=\"193,14 203,9 203,19 193,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" href=\"/en-US/docs/Web/API/AnalyserNode\" aria-current=\"page\">\n    <rect x=\"223\" y=\"0\" width=\"96\" height=\"25\" fill=\"#F4F7F8\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"271\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      AnalyserNode\n    </text>\n  </a></svg>\n<figure class=\"table-container\"><table class=\"properties\">\n  <tbody>\n    <tr>\n      <th scope=\"row\">Number of inputs</th>\n      <td><code>1</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Number of outputs</th>\n      <td><code>1</code> (but may be left unconnected)</td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count mode</th>\n      <td><code>\"max\"</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel count</th>\n      <td><code>2</code></td>\n    </tr>\n    <tr>\n      <th scope=\"row\">Channel interpretation</th>\n      <td><code>\"speakers\"</code></td>\n    </tr>\n  </tbody>\n</table></figure>"}},{"type":"prose","value":{"id":"constructor","title":"Constructor","isH3":false,"content":"<dl>\n  <dt id=\"analysernode\"><a href=\"/en-US/docs/Web/API/AnalyserNode/AnalyserNode\" title=\"AnalyserNode()\"><code>AnalyserNode()</code></a></dt>\n  <dd>\n    <p>Creates a new instance of an <code>AnalyserNode</code> object.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"instance_properties","title":"Instance properties","isH3":false,"content":"<p><em>Inherits properties from its parent, <a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a></em>.</p>\n<dl>\n  <dt id=\"analysernode.fftsize\"><a href=\"/en-US/docs/Web/API/AnalyserNode/fftSize\"><code>AnalyserNode.fftSize</code></a></dt>\n  <dd>\n    <p>An unsigned long value representing the size of the FFT (<a href=\"https://en.wikipedia.org/wiki/Fast_Fourier_transform\" class=\"external\" target=\"_blank\">Fast Fourier Transform</a>) to be used to determine the frequency domain.</p>\n  </dd>\n  <dt id=\"analysernode.frequencybincount\"><a href=\"/en-US/docs/Web/API/AnalyserNode/frequencyBinCount\"><code>AnalyserNode.frequencyBinCount</code></a> <span class=\"badge inline readonly\" title=\"This value may not be changed.\">Read only </span></dt>\n  <dd>\n    <p>An unsigned long value half that of the FFT size. This generally equates to the number of data values you will have to play with for the visualization.</p>\n  </dd>\n  <dt id=\"analysernode.mindecibels\"><a href=\"/en-US/docs/Web/API/AnalyserNode/minDecibels\"><code>AnalyserNode.minDecibels</code></a></dt>\n  <dd>\n    <p>A double value representing the minimum power value in the scaling range for the FFT analysis data, for conversion to unsigned byte values — basically, this specifies the minimum value for the range of results when using <code>getByteFrequencyData()</code>.</p>\n  </dd>\n  <dt id=\"analysernode.maxdecibels\"><a href=\"/en-US/docs/Web/API/AnalyserNode/maxDecibels\"><code>AnalyserNode.maxDecibels</code></a></dt>\n  <dd>\n    <p>A double value representing the maximum power value in the scaling range for the FFT analysis data, for conversion to unsigned byte values — basically, this specifies the maximum value for the range of results when using <code>getByteFrequencyData()</code>.</p>\n  </dd>\n  <dt id=\"analysernode.smoothingtimeconstant\"><a href=\"/en-US/docs/Web/API/AnalyserNode/smoothingTimeConstant\"><code>AnalyserNode.smoothingTimeConstant</code></a></dt>\n  <dd>\n    <p>A double value representing the averaging constant with the last analysis frame — basically, it makes the transition between values over time smoother.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"instance_methods","title":"Instance methods","isH3":false,"content":"<p><em>Inherits methods from its parent, <a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a></em>.</p>\n<dl>\n  <dt id=\"analysernode.getfloatfrequencydata\"><a href=\"/en-US/docs/Web/API/AnalyserNode/getFloatFrequencyData\"><code>AnalyserNode.getFloatFrequencyData()</code></a></dt>\n  <dd>\n    <p>Copies the current frequency data into a <a href=\"/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float32Array\"><code>Float32Array</code></a> array passed into it.</p>\n  </dd>\n  <dt id=\"analysernode.getbytefrequencydata\"><a href=\"/en-US/docs/Web/API/AnalyserNode/getByteFrequencyData\"><code>AnalyserNode.getByteFrequencyData()</code></a></dt>\n  <dd>\n    <p>Copies the current frequency data into a <a href=\"/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array\"><code>Uint8Array</code></a> (unsigned byte array) passed into it.</p>\n  </dd>\n  <dt id=\"analysernode.getfloattimedomaindata\"><a href=\"/en-US/docs/Web/API/AnalyserNode/getFloatTimeDomainData\"><code>AnalyserNode.getFloatTimeDomainData()</code></a></dt>\n  <dd>\n    <p>Copies the current waveform, or time-domain, data into a <a href=\"/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float32Array\"><code>Float32Array</code></a> array passed into it.</p>\n  </dd>\n  <dt id=\"analysernode.getbytetimedomaindata\"><a href=\"/en-US/docs/Web/API/AnalyserNode/getByteTimeDomainData\"><code>AnalyserNode.getByteTimeDomainData()</code></a></dt>\n  <dd>\n    <p>Copies the current waveform, or time-domain, data into a <a href=\"/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array\"><code>Uint8Array</code></a> (unsigned byte array) passed into it.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"examples","title":"Examples","isH3":false,"content":"<div class=\"notecard note\">\n  <p><strong>Note:</strong> See the guide <a href=\"/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API\">Visualizations with Web Audio API</a> for more information on creating audio visualizations.</p>\n</div>"}},{"type":"prose","value":{"id":"basic_usage","title":"Basic usage","isH3":true,"content":"<p>\n  The following example shows basic usage of an <a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a> to create an <code>AnalyserNode</code>, then <a href=\"/en-US/docs/Web/API/Window/requestAnimationFrame\" title=\"requestAnimationFrame\"><code>requestAnimationFrame</code></a> and <a href=\"/en-US/docs/Web/HTML/Element/canvas\"><code>&lt;canvas&gt;</code></a> to collect time domain data repeatedly and draw an \"oscilloscope style\" output of the current audio input.\n  For more complete applied examples/information, check out our <a href=\"https://mdn.github.io/webaudio-examples/voice-change-o-matic/\" class=\"external\" target=\"_blank\">Voice-change-O-matic</a> demo (see <a href=\"https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js#L108-L193\" class=\"external\" target=\"_blank\">app.js lines 108-193</a> for relevant code).\n</p>\n<div class=\"code-example\"><div class=\"example-header\"><span class=\"language-name\">js</span></div><pre class=\"brush: js notranslate\"><code>const audioCtx = new AudioContext();\n\n// …\n\nconst analyser = audioCtx.createAnalyser();\nanalyser.fftSize = 2048;\n\nconst bufferLength = analyser.frequencyBinCount;\nconst dataArray = new Uint8Array(bufferLength);\nanalyser.getByteTimeDomainData(dataArray);\n\n// Connect the source to be analyzed\nsource.connect(analyser);\n\n// Get a canvas defined with ID \"oscilloscope\"\nconst canvas = document.getElementById(\"oscilloscope\");\nconst canvasCtx = canvas.getContext(\"2d\");\n\n// draw an oscilloscope of the current audio source\n\nfunction draw() {\n  requestAnimationFrame(draw);\n\n  analyser.getByteTimeDomainData(dataArray);\n\n  canvasCtx.fillStyle = \"rgb(200 200 200)\";\n  canvasCtx.fillRect(0, 0, canvas.width, canvas.height);\n\n  canvasCtx.lineWidth = 2;\n  canvasCtx.strokeStyle = \"rgb(0 0 0)\";\n\n  canvasCtx.beginPath();\n\n  const sliceWidth = (canvas.width * 1.0) / bufferLength;\n  let x = 0;\n\n  for (let i = 0; i &lt; bufferLength; i++) {\n    const v = dataArray[i] / 128.0;\n    const y = (v * canvas.height) / 2;\n\n    if (i === 0) {\n      canvasCtx.moveTo(x, y);\n    } else {\n      canvasCtx.lineTo(x, y);\n    }\n\n    x += sliceWidth;\n  }\n\n  canvasCtx.lineTo(canvas.width, canvas.height / 2);\n  canvasCtx.stroke();\n}\n\ndraw();\n</code></pre></div>"}},{"type":"specifications","value":{"title":"Specifications","id":"specifications","isH3":false,"specifications":[{"bcdSpecificationURL":"https://webaudio.github.io/web-audio-api/#AnalyserNode","title":"Web Audio API"}],"query":"api.AnalyserNode"}},{"type":"browser_compatibility","value":{"title":"Browser compatibility","id":"browser_compatibility","isH3":false,"query":"api.AnalyserNode"}},{"type":"prose","value":{"id":"see_also","title":"See also","isH3":false,"content":"<ul>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">Using the Web Audio API</a></li>\n</ul>"}}],"toc":[{"text":"Constructor","id":"constructor"},{"text":"Instance properties","id":"instance_properties"},{"text":"Instance methods","id":"instance_methods"},{"text":"Examples","id":"examples"},{"text":"Specifications","id":"specifications"},{"text":"Browser compatibility","id":"browser_compatibility"},{"text":"See also","id":"see_also"}],"summary":"The AnalyserNode interface represents a node able to provide real-time frequency and time-domain analysis information. It is an AudioNode that passes the audio stream unchanged from the input to the output, but allows you to take the generated data, process it, and create audio visualizations.","popularity":0.0053,"modified":"2020-10-15T21:22:20.042Z","other_translations":[],"pageType":"web-api-interface","source":{"folder":"en-us/web/api/analysernode","github_url":"https://github.com/mdn/content/blob/main/files/en-us/web/api/analysernode/index.md","last_commit_url":"https://github.com/mdn/content/commit/null","filename":"index.md"},"short_title":"AnalyserNode","parents":[{"uri":"/en-US/docs/Web","title":"References"},{"uri":"/en-US/docs/Web/API","title":"Web APIs"},{"uri":"/en-US/docs/Web/API/AnalyserNode","title":"AnalyserNode"}],"pageTitle":"AnalyserNode - Web APIs | MDN","noIndexing":false},"url":"/en-US/docs/Web/API/AnalyserNode"}