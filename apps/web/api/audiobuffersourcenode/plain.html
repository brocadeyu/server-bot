<html><head></head><body>
<p>The <strong><code>AudioBufferSourceNode</code></strong> interface is an <a href="/en-US/docs/Web/API/AudioScheduledSourceNode"><code>AudioScheduledSourceNode</code></a> which represents an audio source consisting of in-memory audio data, stored in an <a href="/en-US/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a>.</p>
<p>This interface is especially useful for playing back audio which has particularly stringent timing accuracy requirements, such as for sounds that must match a specific rhythm and can be kept in memory rather than being played from disk or the network. To play sounds which require accurate timing but must be streamed from the network or played from disk, use a <a href="/en-US/docs/Web/API/AudioWorkletNode"><code>AudioWorkletNode</code></a> to implement its playback.</p><svg viewBox="-1 -1 650 42" preserveAspectRatio="xMinYMin meet">
  <a style="text-decoration: none;" href="/en-US/docs/Web/API/EventTarget">
    <rect x="0" y="0" width="88" height="25" fill="#fff" stroke="#D4DDE4" stroke-width="2px"></rect>
    <text x="44" y="16" font-size="10px" fill="#4D4E53" text-anchor="middle">
      EventTarget
    </text>
  </a>
  <line x1="88" y1="14" x2="118" y2="14" stroke="#D4DDE4"></line>
  <polyline points="88,14 98,9 98,19 88,14" stroke="#D4DDE4" fill="#fff"></polyline>
  <a style="text-decoration: none;" href="/en-US/docs/Web/API/AudioNode">
    <rect x="118" y="0" width="75" height="25" fill="#fff" stroke="#D4DDE4" stroke-width="2px"></rect>
    <text x="155.5" y="16" font-size="10px" fill="#4D4E53" text-anchor="middle">
      AudioNode
    </text>
  </a>
  <line x1="193" y1="14" x2="223" y2="14" stroke="#D4DDE4"></line>
  <polyline points="193,14 203,9 203,19 193,14" stroke="#D4DDE4" fill="#fff"></polyline>
  <a style="text-decoration: none;" href="/en-US/docs/Web/API/AudioScheduledSourceNode">
    <rect x="223" y="0" width="192" height="25" fill="#fff" stroke="#D4DDE4" stroke-width="2px"></rect>
    <text x="319" y="16" font-size="10px" fill="#4D4E53" text-anchor="middle">
      AudioScheduledSourceNode
    </text>
  </a>
  <line x1="415" y1="14" x2="445" y2="14" stroke="#D4DDE4"></line>
  <polyline points="415,14 425,9 425,19 415,14" stroke="#D4DDE4" fill="#fff"></polyline>
  <a style="text-decoration: none;" href="/en-US/docs/Web/API/AudioBufferSourceNode" aria-current="page">
    <rect x="445" y="0" width="168" height="25" fill="#F4F7F8" stroke="#D4DDE4" stroke-width="2px"></rect>
    <text x="529" y="16" font-size="10px" fill="#4D4E53" text-anchor="middle">
      AudioBufferSourceNode
    </text>
  </a></svg>
<p>An <code>AudioBufferSourceNode</code> has no inputs and exactly one output, which has the same number of channels as the <code>AudioBuffer</code> indicated by its <a href="/en-US/docs/Web/API/AudioBufferSourceNode/buffer" title="buffer"><code>buffer</code></a> property. If there's no buffer set—that is, if <code>buffer</code> is <code>null</code>—the output contains a single channel of silence (every sample is 0).</p>
<p>An <code>AudioBufferSourceNode</code> can only be played once; after each call to <a href="/en-US/docs/Web/API/AudioBufferSourceNode/start" title="start()"><code>start()</code></a>, you have to create a new node if you want to play the same sound again. Fortunately, these nodes are very inexpensive to create, and the actual <code>AudioBuffer</code>s can be reused for multiple plays of the sound. Indeed, you can use these nodes in a "fire and forget" manner: create the node, call <code>start()</code> to begin playing the sound, and don't even bother to hold a reference to it. It will automatically be garbage-collected at an appropriate time, which won't be until sometime after the sound has finished playing.</p>
<p>Multiple calls to <a href="/en-US/docs/Web/API/AudioScheduledSourceNode/stop" title="stop()"><code>stop()</code></a> are allowed. The most recent call replaces the previous one, if the <code>AudioBufferSourceNode</code> has not already reached the end of the buffer.</p>
<p>
  <img src="/en-US/docs/Web/API/AudioBufferSourceNode/webaudioaudiobuffersourcenode.png" alt="The AudioBufferSourceNode takes the content of an AudioBuffer and m" width="365" height="193">
</p>
<table class="properties">
  <tbody>
    <tr>
      <th scope="row">Number of inputs</th>
      <td><code>0</code></td>
    </tr>
    <tr>
      <th scope="row">Number of outputs</th>
      <td><code>1</code></td>
    </tr>
    <tr>
      <th scope="row">Channel count</th>
      <td>defined by the associated <a href="/en-US/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a></td>
    </tr>
  </tbody>
</table>
<h2 id="constructor">Constructor</h2>
<dl>
  <dt id="audiobuffersourcenode"><a href="/en-US/docs/Web/API/AudioBufferSourceNode/AudioBufferSourceNode" title="AudioBufferSourceNode()"><code>AudioBufferSourceNode()</code></a></dt>
  <dd>
    <p>Creates and returns a new <code>AudioBufferSourceNode</code> object. As an alternative, you can use the <a href="/en-US/docs/Web/API/BaseAudioContext/createBufferSource"><code>BaseAudioContext.createBufferSource()</code></a> factory method; see <a href="/en-US/docs/Web/API/AudioNode#creating_an_audionode">Creating an AudioNode</a>.</p>
  </dd>
</dl>
<h2 id="instance_properties">Instance properties</h2>
<p><em>Inherits properties from its parent, <a href="/en-US/docs/Web/API/AudioScheduledSourceNode"><code>AudioScheduledSourceNode</code></a></em>.</p>
<dl>
  <dt id="audiobuffersourcenode.buffer"><a href="/en-US/docs/Web/API/AudioBufferSourceNode/buffer"><code>AudioBufferSourceNode.buffer</code></a></dt>
  <dd>
    <p>An <a href="/en-US/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a> that defines the audio asset to be played, or when set to the value <code>null</code>, defines a single channel of silence (in which every sample is 0.0).</p>
  </dd>
  <dt id="audiobuffersourcenode.detune"><a href="/en-US/docs/Web/API/AudioBufferSourceNode/detune"><code>AudioBufferSourceNode.detune</code></a></dt>
  <dd>
    <p>A <a href="/en-US/docs/Web/API/AudioParam#k-rate">k-rate</a> <a href="/en-US/docs/Web/API/AudioParam"><code>AudioParam</code></a> representing detuning of playback in <a href="https://en.wikipedia.org/wiki/Cent_%28music%29">cents</a>. This value is compounded with <code>playbackRate</code> to determine the speed at which the sound is played. Its default value is <code>0</code> (meaning no detuning), and its nominal range is -∞ to ∞.</p>
  </dd>
  <dt id="audiobuffersourcenode.loop"><a href="/en-US/docs/Web/API/AudioBufferSourceNode/loop"><code>AudioBufferSourceNode.loop</code></a></dt>
  <dd>
    <p>A Boolean attribute indicating if the audio asset must be replayed when the end of the <a href="/en-US/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a> is reached. Its default value is <code>false</code>.</p>
  </dd>
  <dt id="audiobuffersourcenode.loopstart"><a href="/en-US/docs/Web/API/AudioBufferSourceNode/loopStart"><code>AudioBufferSourceNode.loopStart</code></a> <span class="badge inline optional">Optional</span></dt>
  <dd>
    <p>A floating-point value indicating the time, in seconds, at which playback of the <a href="/en-US/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a> must begin when <code>loop</code> is <code>true</code>. Its default value is <code>0</code> (meaning that at the beginning of each loop, playback begins at the start of the audio buffer).</p>
  </dd>
  <dt id="audiobuffersourcenode.loopend"><a href="/en-US/docs/Web/API/AudioBufferSourceNode/loopEnd"><code>AudioBufferSourceNode.loopEnd</code></a> <span class="badge inline optional">Optional</span></dt>
  <dd>
    <p>A floating-point number indicating the time, in seconds, at which playback of the <a href="/en-US/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a> stops and loops back to the time indicated by <code>loopStart</code>, if <code>loop</code> is <code>true</code>. The default value is <code>0</code>.</p>
  </dd>
  <dt id="audiobuffersourcenode.playbackrate"><a href="/en-US/docs/Web/API/AudioBufferSourceNode/playbackRate"><code>AudioBufferSourceNode.playbackRate</code></a></dt>
  <dd>
    <p>A <a href="/en-US/docs/Web/API/AudioParam#k-rate">k-rate</a> <a href="/en-US/docs/Web/API/AudioParam"><code>AudioParam</code></a> that defines the speed factor at which the audio asset will be played, where a value of 1.0 is the sound's natural sampling rate. Since no pitch correction is applied on the output, this can be used to change the pitch of the sample. This value is compounded with <code>detune</code> to determine the final playback rate.</p>
  </dd>
</dl>
<h2 id="instance_methods">Instance methods</h2>
<p><em>Inherits methods from its parent, <a href="/en-US/docs/Web/API/AudioScheduledSourceNode"><code>AudioScheduledSourceNode</code></a>, and overrides the following method:</em>.</p>
<dl>
  <dt id="start"><a href="/en-US/docs/Web/API/AudioBufferSourceNode/start" title="start()"><code>start()</code></a></dt>
  <dd>
    <p>Schedules playback of the audio data contained in the buffer, or begins playback immediately. Additionally allows the start offset and play duration to be set.</p>
  </dd>
</dl>
<h2 id="examples">Examples</h2>
<p>In this example, we create a two-second buffer, fill it with white noise, and then play it using an <code>AudioBufferSourceNode</code>. The comments should clearly explain what is going on.</p>
<div class="notecard note">
  <p><strong>Note:</strong> You can also <a href="https://mdn.github.io/webaudio-examples/audio-buffer/">run the code live</a>, or <a href="https://github.com/mdn/webaudio-examples/blob/main/audio-buffer/index.html">view the source</a>.</p>
</div>
<pre class="brush: js">const audioCtx = new AudioContext();

// Create an empty three-second stereo buffer at the sample rate of the AudioContext
const myArrayBuffer = audioCtx.createBuffer(
  2,
  audioCtx.sampleRate * 3,
  audioCtx.sampleRate,
);

// Fill the buffer with white noise;
//just random values between -1.0 and 1.0
for (let channel = 0; channel &lt; myArrayBuffer.numberOfChannels; channel++) {
  // This gives us the actual ArrayBuffer that contains the data
  const nowBuffering = myArrayBuffer.getChannelData(channel);
  for (let i = 0; i &lt; myArrayBuffer.length; i++) {
    // Math.random() is in [0; 1.0]
    // audio needs to be in [-1.0; 1.0]
    nowBuffering[i] = Math.random() * 2 - 1;
  }
}

// Get an AudioBufferSourceNode.
// This is the AudioNode to use when we want to play an AudioBuffer
const source = audioCtx.createBufferSource();
// set the buffer in the AudioBufferSourceNode
source.buffer = myArrayBuffer;
// connect the AudioBufferSourceNode to the
// destination so we can hear the sound
source.connect(audioCtx.destination);
// start the source playing
source.start();
</pre>
<div class="notecard note">
  <p><strong>Note:</strong> For a <code>decodeAudioData()</code> example, see the <a href="/en-US/docs/Web/API/BaseAudioContext/decodeAudioData" title="AudioContext.decodeAudioData()"><code>AudioContext.decodeAudioData()</code></a> page.</p>
</div>
<h2 id="specifications">Specifications</h2><div class="bc-specs" data-bcd-query="api.AudioBufferSourceNode" data-spec-urls="">
  If you're able to see this, something went wrong on this page.
</div>
<h2 id="browser_compatibility">Browser compatibility</h2><div class="bc-data" data-query="api.AudioBufferSourceNode" data-depth="1" data-multiple="false">
  If you're able to see this, something went wrong on this page.
</div>
<h2 id="see_also">See also</h2>
<ul>
  <li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a></li>
  <li><a href="/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a></li>
</ul>
</body></html>