{"doc":{"isMarkdown":true,"isTranslated":false,"isActive":true,"flaws":{},"title":"OfflineAudioContext","mdn_url":"/en-US/docs/Web/API/OfflineAudioContext","locale":"en-US","native":"English (US)","browserCompat":["api.OfflineAudioContext"],"baseline":{"baseline":"high","baseline_high_date":"2023-10-26","baseline_low_date":"2021-04-26","support":{"chrome":"35","chrome_android":"35","edge":"12","firefox":"25","firefox_android":"25","safari":"14.1","safari_ios":"14.5"}},"sidebarHTML":"<ol><li class=\"section\"><a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a></li><li class=\"section\"><em><a href=\"/en-US/docs/Web/API/OfflineAudioContext\" aria-current=\"page\"><code>OfflineAudioContext</code></a></em></li><li class=\"toggle\"><details open=\"\"><summary>Constructor</summary><ol><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/OfflineAudioContext\"><code>OfflineAudioContext()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Instance properties</summary><ol><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/length\"><code>length</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Instance methods</summary><ol><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/resume\"><code>resume()</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/startRendering\"><code>startRendering()</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/suspend\"><code>suspend()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Events</summary><ol><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/complete_event\"><code>complete</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Inheritance</summary><ol><li><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/EventTarget\"><code>EventTarget</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Related pages for Web Audio API</summary><ol><li><a href=\"/en-US/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioListener\"><code>AudioListener</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioParam\"><code>AudioParam</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a><abbr class=\"icon icon-deprecated\" title=\"Deprecated. Not for use in new websites.\">\n  <span class=\"visually-hidden\">Deprecated</span>\n</abbr></li><li><a href=\"/en-US/docs/Web/API/AudioScheduledSourceNode\"><code>AudioScheduledSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioSinkInfo\"><code>AudioSinkInfo</code></a><abbr class=\"icon icon-experimental\" title=\"Experimental. Expect behavior to change in the future.\">\n    <span class=\"visually-hidden\">Experimental</span>\n</abbr></li><li><a href=\"/en-US/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope\"><code>AudioWorkletGlobalScope</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConstantSourceNode\"><code>ConstantSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/GainNode\"><code>GainNode</code></a></li><li><a href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></li><li><a href=\"/en-US/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code></a></li></ol></details></li></ol>","sidebarMacro":"APIRef","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>The <code>OfflineAudioContext</code> interface is an <a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a> interface representing an audio-processing graph built from linked together <a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a>s. In contrast with a standard <a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a>, an <code>OfflineAudioContext</code> doesn't render the audio to the device hardware; instead, it generates it, as fast as it can, and outputs the result to an <a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a>.</p><svg viewBox=\"-1 -1 650 42\" preserveAspectRatio=\"xMinYMin meet\">\n  <a style=\"text-decoration: none;\" href=\"/en-US/docs/Web/API/EventTarget\">\n    <rect x=\"0\" y=\"0\" width=\"88\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"44\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      EventTarget\n    </text>\n  </a>\n  <line x1=\"88\" y1=\"14\" x2=\"118\" y2=\"14\" stroke=\"#D4DDE4\"></line>\n  <polyline points=\"88,14 98,9 98,19 88,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" href=\"/en-US/docs/Web/API/BaseAudioContext\">\n    <rect x=\"118\" y=\"0\" width=\"128\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"182\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      BaseAudioContext\n    </text>\n  </a>\n  <line x1=\"246\" y1=\"14\" x2=\"276\" y2=\"14\" stroke=\"#D4DDE4\"></line>\n  <polyline points=\"246,14 256,9 256,19 246,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" href=\"/en-US/docs/Web/API/OfflineAudioContext\" aria-current=\"page\">\n    <rect x=\"276\" y=\"0\" width=\"152\" height=\"25\" fill=\"#F4F7F8\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"352\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      OfflineAudioContext\n    </text>\n  </a></svg>"}},{"type":"prose","value":{"id":"constructor","title":"Constructor","isH3":false,"content":"<dl>\n  <dt id=\"offlineaudiocontext\"><a href=\"/en-US/docs/Web/API/OfflineAudioContext/OfflineAudioContext\" title=\"OfflineAudioContext()\"><code>OfflineAudioContext()</code></a></dt>\n  <dd>\n    <p>Creates a new <code>OfflineAudioContext</code> instance.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"instance_properties","title":"Instance properties","isH3":false,"content":"<p><em>Also inherits properties from its parent interface, <a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a>.</em></p>\n<dl>\n  <dt id=\"offlineaudiocontext.length\"><a href=\"/en-US/docs/Web/API/OfflineAudioContext/length\"><code>OfflineAudioContext.length</code></a> <span class=\"badge inline readonly\" title=\"This value may not be changed.\">Read only </span></dt>\n  <dd>\n    <p>An integer representing the size of the buffer in sample-frames.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"instance_methods","title":"Instance methods","isH3":false,"content":"<p><em>Also inherits methods from its parent interface, <a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a>.</em></p>\n<dl>\n  <dt id=\"offlineaudiocontext.suspend\"><a href=\"/en-US/docs/Web/API/OfflineAudioContext/suspend\"><code>OfflineAudioContext.suspend()</code></a></dt>\n  <dd>\n    <p>Schedules a suspension of the time progression in the audio context at the specified time and returns a promise.</p>\n  </dd>\n  <dt id=\"offlineaudiocontext.startrendering\"><a href=\"/en-US/docs/Web/API/OfflineAudioContext/startRendering\"><code>OfflineAudioContext.startRendering()</code></a></dt>\n  <dd>\n    <p>Starts rendering the audio, taking into account the current connections and the current scheduled changes. This page covers both the event-based version and the promise-based version.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"deprecated_methods","title":"Deprecated methods","isH3":true,"content":"<dl>\n  <dt id=\"offlineaudiocontext.resume\"><a href=\"/en-US/docs/Web/API/OfflineAudioContext/resume\"><code>OfflineAudioContext.resume()</code></a></dt>\n  <dd>\n    <p>Resumes the progression of time in an audio context that has previously been suspended.</p>\n  </dd>\n</dl>\n<div class=\"notecard note\">\n  <p><strong>Note:</strong> The <code>resume()</code> method is still available — it is now defined on the <a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a> interface (see <a href=\"/en-US/docs/Web/API/AudioContext/resume\"><code>AudioContext.resume</code></a>) and thus can be accessed by both the <a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a> and <code>OfflineAudioContext</code> interfaces.</p>\n</div>"}},{"type":"prose","value":{"id":"events","title":"Events","isH3":false,"content":"<p>Listen to these events using <a href=\"/en-US/docs/Web/API/EventTarget/addEventListener\"><code>addEventListener()</code></a> or by assigning an event listener to the <code>oneventname</code> property of this interface:</p>\n<dl>\n  <dt id=\"complete\"><a href=\"/en-US/docs/Web/API/OfflineAudioContext/complete_event\"><code>complete</code></a></dt>\n  <dd>\n    <p>Fired when the rendering of an offline audio context is complete.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"examples","title":"Examples","isH3":false,"content":""}},{"type":"prose","value":{"id":"playing_audio_with_an_offline_audio_context","title":"Playing audio with an offline audio context","isH3":true,"content":"<p>In this example, we declare both an <a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a> and an <code>OfflineAudioContext</code> object. We use the <code>AudioContext</code> to load an audio track <a href=\"/en-US/docs/Web/API/Window/fetch\" title=\"fetch()\"><code>fetch()</code></a>, then the <code>OfflineAudioContext</code> to render the audio into an <a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a> and play the track through. After the offline audio graph is set up, we render it to an <a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> using <code>OfflineAudioContext.startRendering()</code>.</p>\n<p>When the <code>startRendering()</code> promise resolves, rendering has completed and the output <code>AudioBuffer</code> is returned out of the promise.</p>\n<p>At this point we create another audio context, create an <a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a> inside it, and set its buffer to be equal to the promise <code>AudioBuffer</code>. This is then played as part of a simple standard audio graph.</p>\n<div class=\"notecard note\">\n  <p><strong>Note:</strong> You can <a href=\"https://mdn.github.io/webaudio-examples/offline-audio-context-promise/\" class=\"external\" target=\"_blank\">run the full example live</a>, or <a href=\"https://github.com/mdn/webaudio-examples/tree/main/offline-audio-context-promise\" class=\"external\" target=\"_blank\">view the source</a>.</p>\n</div>\n<div class=\"code-example\"><div class=\"example-header\"><span class=\"language-name\">js</span></div><pre class=\"brush: js notranslate\"><code>// Define both online and offline audio contexts\nlet audioCtx; // Must be initialized after a user interaction\nconst offlineCtx = new OfflineAudioContext(2, 44100 * 40, 44100);\n\n// Define constants for dom nodes\nconst play = document.querySelector(\"#play\");\n\nfunction getData() {\n  // Fetch an audio track, decode it and stick it in a buffer.\n  // Then we put the buffer into the source and can play it.\n  fetch(\"viper.ogg\")\n    .then((response) =&gt; response.arrayBuffer())\n    .then((downloadedBuffer) =&gt; audioCtx.decodeAudioData(downloadedBuffer))\n    .then((decodedBuffer) =&gt; {\n      console.log(\"File downloaded successfully.\");\n      const source = new AudioBufferSourceNode(offlineCtx, {\n        buffer: decodedBuffer,\n      });\n      source.connect(offlineCtx.destination);\n      return source.start();\n    })\n    .then(() =&gt; offlineCtx.startRendering())\n    .then((renderedBuffer) =&gt; {\n      console.log(\"Rendering completed successfully.\");\n      play.disabled = false;\n      const song = new AudioBufferSourceNode(audioCtx, {\n        buffer: renderedBuffer,\n      });\n      song.connect(audioCtx.destination);\n\n      // Start the song\n      song.start();\n    })\n    .catch((err) =&gt; {\n      console.error(`Error encountered: ${err}`);\n    });\n}\n\n// Activate the play button\nplay.onclick = () =&gt; {\n  play.disabled = true;\n  // We can initialize the context as the user clicked.\n  audioCtx = new AudioContext();\n\n  // Fetch the data and start the song\n  getData();\n};\n</code></pre></div>"}},{"type":"specifications","value":{"title":"Specifications","id":"specifications","isH3":false,"specifications":[{"bcdSpecificationURL":"https://webaudio.github.io/web-audio-api/#OfflineAudioContext","title":"Web Audio API"}],"query":"api.OfflineAudioContext"}},{"type":"browser_compatibility","value":{"title":"Browser compatibility","id":"browser_compatibility","isH3":false,"query":"api.OfflineAudioContext"}},{"type":"prose","value":{"id":"see_also","title":"See also","isH3":false,"content":"<ul>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">Using the Web Audio API</a></li>\n</ul>"}}],"toc":[{"text":"Constructor","id":"constructor"},{"text":"Instance properties","id":"instance_properties"},{"text":"Instance methods","id":"instance_methods"},{"text":"Events","id":"events"},{"text":"Examples","id":"examples"},{"text":"Specifications","id":"specifications"},{"text":"Browser compatibility","id":"browser_compatibility"},{"text":"See also","id":"see_also"}],"summary":"The OfflineAudioContext interface is an AudioContext interface representing an audio-processing graph built from linked together AudioNodes. In contrast with a standard AudioContext, an OfflineAudioContext doesn't render the audio to the device hardware; instead, it generates it, as fast as it can, and outputs the result to an AudioBuffer.","popularity":0.0024,"modified":"2020-10-15T21:24:13.926Z","other_translations":[],"pageType":"web-api-interface","source":{"folder":"en-us/web/api/offlineaudiocontext","github_url":"https://github.com/mdn/content/blob/main/files/en-us/web/api/offlineaudiocontext/index.md","last_commit_url":"https://github.com/mdn/content/commit/null","filename":"index.md"},"short_title":"OfflineAudioContext","parents":[{"uri":"/en-US/docs/Web","title":"References"},{"uri":"/en-US/docs/Web/API","title":"Web APIs"},{"uri":"/en-US/docs/Web/API/OfflineAudioContext","title":"OfflineAudioContext"}],"pageTitle":"OfflineAudioContext - Web APIs | MDN","noIndexing":false},"url":"/en-US/docs/Web/API/OfflineAudioContext"}