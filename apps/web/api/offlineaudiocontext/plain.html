<html><head></head><body>
<p>The <code>OfflineAudioContext</code> interface is an <a href="/en-US/docs/Web/API/AudioContext"><code>AudioContext</code></a> interface representing an audio-processing graph built from linked together <a href="/en-US/docs/Web/API/AudioNode"><code>AudioNode</code></a>s. In contrast with a standard <a href="/en-US/docs/Web/API/AudioContext"><code>AudioContext</code></a>, an <code>OfflineAudioContext</code> doesn't render the audio to the device hardware; instead, it generates it, as fast as it can, and outputs the result to an <a href="/en-US/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a>.</p><svg viewBox="-1 -1 650 42" preserveAspectRatio="xMinYMin meet">
  <a style="text-decoration: none;" href="/en-US/docs/Web/API/EventTarget">
    <rect x="0" y="0" width="88" height="25" fill="#fff" stroke="#D4DDE4" stroke-width="2px"></rect>
    <text x="44" y="16" font-size="10px" fill="#4D4E53" text-anchor="middle">
      EventTarget
    </text>
  </a>
  <line x1="88" y1="14" x2="118" y2="14" stroke="#D4DDE4"></line>
  <polyline points="88,14 98,9 98,19 88,14" stroke="#D4DDE4" fill="#fff"></polyline>
  <a style="text-decoration: none;" href="/en-US/docs/Web/API/BaseAudioContext">
    <rect x="118" y="0" width="128" height="25" fill="#fff" stroke="#D4DDE4" stroke-width="2px"></rect>
    <text x="182" y="16" font-size="10px" fill="#4D4E53" text-anchor="middle">
      BaseAudioContext
    </text>
  </a>
  <line x1="246" y1="14" x2="276" y2="14" stroke="#D4DDE4"></line>
  <polyline points="246,14 256,9 256,19 246,14" stroke="#D4DDE4" fill="#fff"></polyline>
  <a style="text-decoration: none;" href="/en-US/docs/Web/API/OfflineAudioContext" aria-current="page">
    <rect x="276" y="0" width="152" height="25" fill="#F4F7F8" stroke="#D4DDE4" stroke-width="2px"></rect>
    <text x="352" y="16" font-size="10px" fill="#4D4E53" text-anchor="middle">
      OfflineAudioContext
    </text>
  </a></svg>
<h2 id="constructor">Constructor</h2>
<dl>
  <dt id="offlineaudiocontext"><a href="/en-US/docs/Web/API/OfflineAudioContext/OfflineAudioContext" title="OfflineAudioContext()"><code>OfflineAudioContext()</code></a></dt>
  <dd>
    <p>Creates a new <code>OfflineAudioContext</code> instance.</p>
  </dd>
</dl>
<h2 id="instance_properties">Instance properties</h2>
<p><em>Also inherits properties from its parent interface, <a href="/en-US/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a>.</em></p>
<dl>
  <dt id="offlineaudiocontext.length"><a href="/en-US/docs/Web/API/OfflineAudioContext/length"><code>OfflineAudioContext.length</code></a> <span class="badge inline readonly" title="This value may not be changed.">Read only </span></dt>
  <dd>
    <p>An integer representing the size of the buffer in sample-frames.</p>
  </dd>
</dl>
<h2 id="instance_methods">Instance methods</h2>
<p><em>Also inherits methods from its parent interface, <a href="/en-US/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a>.</em></p>
<dl>
  <dt id="offlineaudiocontext.suspend"><a href="/en-US/docs/Web/API/OfflineAudioContext/suspend"><code>OfflineAudioContext.suspend()</code></a></dt>
  <dd>
    <p>Schedules a suspension of the time progression in the audio context at the specified time and returns a promise.</p>
  </dd>
  <dt id="offlineaudiocontext.startrendering"><a href="/en-US/docs/Web/API/OfflineAudioContext/startRendering"><code>OfflineAudioContext.startRendering()</code></a></dt>
  <dd>
    <p>Starts rendering the audio, taking into account the current connections and the current scheduled changes. This page covers both the event-based version and the promise-based version.</p>
  </dd>
</dl>
<h3 id="deprecated_methods">Deprecated methods</h3>
<dl>
  <dt id="offlineaudiocontext.resume"><a href="/en-US/docs/Web/API/OfflineAudioContext/resume"><code>OfflineAudioContext.resume()</code></a></dt>
  <dd>
    <p>Resumes the progression of time in an audio context that has previously been suspended.</p>
  </dd>
</dl>
<div class="notecard note">
  <p><strong>Note:</strong> The <code>resume()</code> method is still available â€” it is now defined on the <a href="/en-US/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a> interface (see <a href="/en-US/docs/Web/API/AudioContext/resume"><code>AudioContext.resume</code></a>) and thus can be accessed by both the <a href="/en-US/docs/Web/API/AudioContext"><code>AudioContext</code></a> and <code>OfflineAudioContext</code> interfaces.</p>
</div>
<h2 id="events">Events</h2>
<p>Listen to these events using <a href="/en-US/docs/Web/API/EventTarget/addEventListener"><code>addEventListener()</code></a> or by assigning an event listener to the <code>oneventname</code> property of this interface:</p>
<dl>
  <dt id="complete"><a href="/en-US/docs/Web/API/OfflineAudioContext/complete_event"><code>complete</code></a></dt>
  <dd>
    <p>Fired when the rendering of an offline audio context is complete.</p>
  </dd>
</dl>
<h2 id="examples">Examples</h2>
<h3 id="playing_audio_with_an_offline_audio_context">Playing audio with an offline audio context</h3>
<p>In this example, we declare both an <a href="/en-US/docs/Web/API/AudioContext"><code>AudioContext</code></a> and an <code>OfflineAudioContext</code> object. We use the <code>AudioContext</code> to load an audio track <a href="/en-US/docs/Web/API/Window/fetch" title="fetch()"><code>fetch()</code></a>, then the <code>OfflineAudioContext</code> to render the audio into an <a href="/en-US/docs/Web/API/AudioBufferSourceNode"><code>AudioBufferSourceNode</code></a> and play the track through. After the offline audio graph is set up, we render it to an <a href="/en-US/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a> using <code>OfflineAudioContext.startRendering()</code>.</p>
<p>When the <code>startRendering()</code> promise resolves, rendering has completed and the output <code>AudioBuffer</code> is returned out of the promise.</p>
<p>At this point we create another audio context, create an <a href="/en-US/docs/Web/API/AudioBufferSourceNode"><code>AudioBufferSourceNode</code></a> inside it, and set its buffer to be equal to the promise <code>AudioBuffer</code>. This is then played as part of a simple standard audio graph.</p>
<div class="notecard note">
  <p><strong>Note:</strong> You can <a href="https://mdn.github.io/webaudio-examples/offline-audio-context-promise/">run the full example live</a>, or <a href="https://github.com/mdn/webaudio-examples/tree/main/offline-audio-context-promise">view the source</a>.</p>
</div>
<pre class="brush: js">// Define both online and offline audio contexts
let audioCtx; // Must be initialized after a user interaction
const offlineCtx = new OfflineAudioContext(2, 44100 * 40, 44100);

// Define constants for dom nodes
const play = document.querySelector("#play");

function getData() {
  // Fetch an audio track, decode it and stick it in a buffer.
  // Then we put the buffer into the source and can play it.
  fetch("viper.ogg")
    .then((response) =&gt; response.arrayBuffer())
    .then((downloadedBuffer) =&gt; audioCtx.decodeAudioData(downloadedBuffer))
    .then((decodedBuffer) =&gt; {
      console.log("File downloaded successfully.");
      const source = new AudioBufferSourceNode(offlineCtx, {
        buffer: decodedBuffer,
      });
      source.connect(offlineCtx.destination);
      return source.start();
    })
    .then(() =&gt; offlineCtx.startRendering())
    .then((renderedBuffer) =&gt; {
      console.log("Rendering completed successfully.");
      play.disabled = false;
      const song = new AudioBufferSourceNode(audioCtx, {
        buffer: renderedBuffer,
      });
      song.connect(audioCtx.destination);

      // Start the song
      song.start();
    })
    .catch((err) =&gt; {
      console.error(`Error encountered: ${err}`);
    });
}

// Activate the play button
play.onclick = () =&gt; {
  play.disabled = true;
  // We can initialize the context as the user clicked.
  audioCtx = new AudioContext();

  // Fetch the data and start the song
  getData();
};
</pre>
<h2 id="specifications">Specifications</h2><div class="bc-specs" data-bcd-query="api.OfflineAudioContext" data-spec-urls="">
  If you're able to see this, something went wrong on this page.
</div>
<h2 id="browser_compatibility">Browser compatibility</h2><div class="bc-data" data-query="api.OfflineAudioContext" data-depth="1" data-multiple="false">
  If you're able to see this, something went wrong on this page.
</div>
<h2 id="see_also">See also</h2>
<ul>
  <li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a></li>
</ul>
</body></html>