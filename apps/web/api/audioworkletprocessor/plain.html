<html><head></head><body>
<p>The <strong><code>AudioWorkletProcessor</code></strong> interface of the <a href="/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a> represents an audio processing code behind a custom <a href="/en-US/docs/Web/API/AudioWorkletNode"><code>AudioWorkletNode</code></a>. It lives in the <a href="/en-US/docs/Web/API/AudioWorkletGlobalScope"><code>AudioWorkletGlobalScope</code></a> and runs on the Web Audio rendering thread. In turn, an <a href="/en-US/docs/Web/API/AudioWorkletNode"><code>AudioWorkletNode</code></a> based on it runs on the main thread.</p>
<h2 id="constructor">Constructor</h2>
<div class="notecard note">
  <p><strong>Note:</strong> The <code>AudioWorkletProcessor</code> and classes that derive from it cannot be instantiated directly from a user-supplied code. Instead, they are created only internally by the creation of an associated <a href="/en-US/docs/Web/API/AudioWorkletNode"><code>AudioWorkletNode</code></a>s. The constructor of the deriving class is getting called with an options object, so you can perform a custom initialization procedures â€” see constructor page for details.</p>
</div>
<dl>
  <dt id="audioworkletprocessor"><a href="/en-US/docs/Web/API/AudioWorkletProcessor/AudioWorkletProcessor" title="AudioWorkletProcessor()"><code>AudioWorkletProcessor()</code></a></dt>
  <dd>
    <p>Creates a new instance of an <code>AudioWorkletProcessor</code> object.</p>
  </dd>
</dl>
<h2 id="instance_properties">Instance properties</h2>
<dl>
  <dt id="port"><a href="/en-US/docs/Web/API/AudioWorkletProcessor/port" title="port"><code>port</code></a> <span class="badge inline readonly" title="This value may not be changed.">Read only </span></dt>
  <dd>
    <p>Returns a <a href="/en-US/docs/Web/API/MessagePort"><code>MessagePort</code></a> used for bidirectional communication between the processor and the <a href="/en-US/docs/Web/API/AudioWorkletNode"><code>AudioWorkletNode</code></a> which it belongs to. The other end is available under the <a href="/en-US/docs/Web/API/AudioWorkletNode/port" title="port"><code>port</code></a> property of the node.</p>
  </dd>
</dl>
<h2 id="instance_methods">Instance methods</h2>
<p><em>The <code>AudioWorkletProcessor</code> interface does not define any methods of its own. However, you must provide a <a href="/en-US/docs/Web/API/AudioWorkletProcessor/process" title="process()"><code>process()</code></a> method, which is called in order to process the audio stream.</em></p>
<h2 id="events">Events</h2>
<p><em>The <code>AudioWorkletProcessor</code> interface doesn't respond to any events.</em></p>
<h2 id="usage_notes">Usage notes</h2>
<h3 id="deriving_classes">Deriving classes</h3>
<p>To define custom audio processing code you have to derive a class from the <code>AudioWorkletProcessor</code> interface. Although not defined on the interface, the deriving class must have the <a href="/en-US/docs/Web/API/AudioWorkletProcessor/process" title="process"><code>process</code></a> method. This method gets called for each block of 128 sample-frames and takes input and output arrays and calculated values of custom <a href="/en-US/docs/Web/API/AudioParam"><code>AudioParam</code></a>s (if they are defined) as parameters. You can use inputs and audio parameter values to fill the outputs array, which by default holds silence.</p>
<p>Optionally, if you want custom <a href="/en-US/docs/Web/API/AudioParam"><code>AudioParam</code></a>s on your node, you can supply a <a href="/en-US/docs/Web/API/AudioWorkletProcessor/parameterDescriptors" title="parameterDescriptors"><code>parameterDescriptors</code></a> property as a <em>static getter</em> on the processor. The array of <a href="/en-US/docs/Web/API/AudioParamDescriptor"><code>AudioParamDescriptor</code></a>-based objects returned is used internally to create the <a href="/en-US/docs/Web/API/AudioParam"><code>AudioParam</code></a>s during the instantiation of the <code>AudioWorkletNode</code>.</p>
<p>The resulting <code>AudioParam</code>s reside in the <a href="/en-US/docs/Web/API/AudioWorkletNode/parameters" title="parameters"><code>parameters</code></a> property of the node and can be automated using standard methods such as <a href="/en-US/docs/Web/API/AudioParam/linearRampToValueAtTime"><code>linearRampToValueAtTime</code></a>. Their calculated values will be passed into the <a href="/en-US/docs/Web/API/AudioWorkletProcessor/process" title="process()"><code>process()</code></a> method of the processor for you to shape the node output accordingly.</p>
<h3 id="processing_audio">Processing audio</h3>
<p>An example algorithm of creating a custom audio processing mechanism is:</p>
<ol>
  <li>
    <p>Create a separate file;</p>
  </li>
  <li>
    <p>In the file:</p>
    <ol>
      <li>Extend the <code>AudioWorkletProcessor</code> class (see <a href="#deriving_classes">"Deriving classes" section</a>) and supply your own <a href="/en-US/docs/Web/API/AudioWorkletProcessor/process" title="process()"><code>process()</code></a> method in it;</li>
      <li>Register the processor using <a href="/en-US/docs/Web/API/AudioWorkletGlobalScope/registerProcessor"><code>AudioWorkletGlobalScope.registerProcessor()</code></a> method;</li>
    </ol>
  </li>
  <li>
    <p>Load the file using <a href="/en-US/docs/Web/API/Worklet/addModule" title="addModule()"><code>addModule()</code></a> method on your audio context's <a href="/en-US/docs/Web/API/BaseAudioContext/audioWorklet" title="audioWorklet"><code>audioWorklet</code></a> property;</p>
  </li>
  <li>
    <p>Create an <a href="/en-US/docs/Web/API/AudioWorkletNode"><code>AudioWorkletNode</code></a> based on the processor. The processor will be instantiated internally by the <code>AudioWorkletNode</code> constructor.</p>
  </li>
  <li>
    <p>Connect the node to the other nodes.</p>
  </li>
</ol>
<h2 id="examples">Examples</h2>
<p>In the example below we create a custom <a href="/en-US/docs/Web/API/AudioWorkletNode"><code>AudioWorkletNode</code></a> that outputs white noise.</p>
<p>First, we need to define a custom <code>AudioWorkletProcessor</code>, which will output white noise, and register it. Note that this should be done in a separate file.</p>
<pre class="brush: js">// white-noise-processor.js
class WhiteNoiseProcessor extends AudioWorkletProcessor {
  process(inputs, outputs, parameters) {
    const output = outputs[0];
    output.forEach((channel) =&gt; {
      for (let i = 0; i &lt; channel.length; i++) {
        channel[i] = Math.random() * 2 - 1;
      }
    });
    return true;
  }
}

registerProcessor("white-noise-processor", WhiteNoiseProcessor);
</pre>
<p>Next, in our main script file we'll load the processor, create an instance of <a href="/en-US/docs/Web/API/AudioWorkletNode"><code>AudioWorkletNode</code></a>, passing it the name of the processor, then connect the node to an audio graph.</p>
<pre class="brush: js">const audioContext = new AudioContext();
await audioContext.audioWorklet.addModule("white-noise-processor.js");
const whiteNoiseNode = new AudioWorkletNode(
  audioContext,
  "white-noise-processor",
);
whiteNoiseNode.connect(audioContext.destination);
</pre>
<h2 id="specifications">Specifications</h2><div class="bc-specs" data-bcd-query="api.AudioWorkletProcessor" data-spec-urls="">
  If you're able to see this, something went wrong on this page.
</div>
<h2 id="browser_compatibility">Browser compatibility</h2><div class="bc-data" data-query="api.AudioWorkletProcessor" data-depth="1" data-multiple="false">
  If you're able to see this, something went wrong on this page.
</div>
<h2 id="see_also">See also</h2>
<ul>
  <li><a href="/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a></li>
  <li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a></li>
  <li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_AudioWorklet">Using AudioWorklet</a></li>
</ul>
</body></html>