<html><head></head><body>
<p>The <code>AudioContext</code> interface represents an audio-processing graph built from audio modules linked together, each represented by an <a href="/en-US/docs/Web/API/AudioNode"><code>AudioNode</code></a>.</p>
<p>An audio context controls both the creation of the nodes it contains and the execution of the audio processing, or decoding. You need to create an <code>AudioContext</code> before you do anything else, as everything happens inside a context. It's recommended to create one AudioContext and reuse it instead of initializing a new one each time, and it's OK to use a single <code>AudioContext</code> for several different audio sources and pipeline concurrently.</p><svg viewBox="-1 -1 650 42" preserveAspectRatio="xMinYMin meet">
  <a style="text-decoration: none;" href="/en-US/docs/Web/API/EventTarget">
    <rect x="0" y="0" width="88" height="25" fill="#fff" stroke="#D4DDE4" stroke-width="2px"></rect>
    <text x="44" y="16" font-size="10px" fill="#4D4E53" text-anchor="middle">
      EventTarget
    </text>
  </a>
  <line x1="88" y1="14" x2="118" y2="14" stroke="#D4DDE4"></line>
  <polyline points="88,14 98,9 98,19 88,14" stroke="#D4DDE4" fill="#fff"></polyline>
  <a style="text-decoration: none;" href="/en-US/docs/Web/API/BaseAudioContext">
    <rect x="118" y="0" width="128" height="25" fill="#fff" stroke="#D4DDE4" stroke-width="2px"></rect>
    <text x="182" y="16" font-size="10px" fill="#4D4E53" text-anchor="middle">
      BaseAudioContext
    </text>
  </a>
  <line x1="246" y1="14" x2="276" y2="14" stroke="#D4DDE4"></line>
  <polyline points="246,14 256,9 256,19 246,14" stroke="#D4DDE4" fill="#fff"></polyline>
  <a style="text-decoration: none;" href="/en-US/docs/Web/API/AudioContext" aria-current="page">
    <rect x="276" y="0" width="96" height="25" fill="#F4F7F8" stroke="#D4DDE4" stroke-width="2px"></rect>
    <text x="324" y="16" font-size="10px" fill="#4D4E53" text-anchor="middle">
      AudioContext
    </text>
  </a></svg>
<h2 id="constructor">Constructor</h2>
<dl>
  <dt id="audiocontext"><a href="/en-US/docs/Web/API/AudioContext/AudioContext" title="AudioContext()"><code>AudioContext()</code></a></dt>
  <dd>
    <p>Creates and returns a new <code>AudioContext</code> object.</p>
  </dd>
</dl>
<h2 id="instance_properties">Instance properties</h2>
<p><em>Also inherits properties from its parent interface, <a href="/en-US/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a>.</em></p>
<dl>
  <dt id="audiocontext.baselatency"><a href="/en-US/docs/Web/API/AudioContext/baseLatency"><code>AudioContext.baseLatency</code></a> <span class="badge inline readonly" title="This value may not be changed.">Read only </span></dt>
  <dd>
    <p>Returns the number of seconds of processing latency incurred by the <code>AudioContext</code> passing the audio from the <a href="/en-US/docs/Web/API/AudioDestinationNode"><code>AudioDestinationNode</code></a> to the audio subsystem.</p>
  </dd>
  <dt id="audiocontext.outputlatency"><a href="/en-US/docs/Web/API/AudioContext/outputLatency"><code>AudioContext.outputLatency</code></a> <span class="badge inline readonly" title="This value may not be changed.">Read only </span></dt>
  <dd>
    <p>Returns an estimation of the output latency of the current audio context.</p>
  </dd>
  <dt id="audiocontext.sinkid"><a href="/en-US/docs/Web/API/AudioContext/sinkId"><code>AudioContext.sinkId</code></a> <span class="badge inline readonly" title="This value may not be changed.">Read only </span> <abbr class="icon icon-experimental" title="Experimental. Expect behavior to change in the future.">
    <span class="visually-hidden">Experimental</span>
</abbr> <span class="badge inline secure" title="This feature is available only in secure contexts (HTTPS)">Secure context</span></dt>
  <dd>
    <p>Returns the sink ID of the current output audio device.</p>
  </dd>
</dl>
<h2 id="instance_methods">Instance methods</h2>
<p><em>Also inherits methods from its parent interface, <a href="/en-US/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a>.</em></p>
<dl>
  <dt id="audiocontext.close"><a href="/en-US/docs/Web/API/AudioContext/close"><code>AudioContext.close()</code></a></dt>
  <dd>
    <p>Closes the audio context, releasing any system audio resources that it uses.</p>
  </dd>
  <dt id="audiocontext.createmediaelementsource"><a href="/en-US/docs/Web/API/AudioContext/createMediaElementSource"><code>AudioContext.createMediaElementSource()</code></a></dt>
  <dd>
    <p>Creates a <a href="/en-US/docs/Web/API/MediaElementAudioSourceNode"><code>MediaElementAudioSourceNode</code></a> associated with an <a href="/en-US/docs/Web/API/HTMLMediaElement"><code>HTMLMediaElement</code></a>. This can be used to play and manipulate audio from <a href="/en-US/docs/Web/HTML/Element/video"><code>&lt;video&gt;</code></a> or <a href="/en-US/docs/Web/HTML/Element/audio"><code>&lt;audio&gt;</code></a> elements.</p>
  </dd>
  <dt id="audiocontext.createmediastreamsource"><a href="/en-US/docs/Web/API/AudioContext/createMediaStreamSource"><code>AudioContext.createMediaStreamSource()</code></a></dt>
  <dd>
    <p>Creates a <a href="/en-US/docs/Web/API/MediaStreamAudioSourceNode"><code>MediaStreamAudioSourceNode</code></a> associated with a <a href="/en-US/docs/Web/API/MediaStream"><code>MediaStream</code></a> representing an audio stream which may come from the local computer microphone or other sources.</p>
  </dd>
  <dt id="audiocontext.createmediastreamdestination"><a href="/en-US/docs/Web/API/AudioContext/createMediaStreamDestination"><code>AudioContext.createMediaStreamDestination()</code></a></dt>
  <dd>
    <p>Creates a <a href="/en-US/docs/Web/API/MediaStreamAudioDestinationNode"><code>MediaStreamAudioDestinationNode</code></a> associated with a <a href="/en-US/docs/Web/API/MediaStream"><code>MediaStream</code></a> representing an audio stream which may be stored in a local file or sent to another computer.</p>
  </dd>
  <dt id="audiocontext.createmediastreamtracksource"><a href="/en-US/docs/Web/API/AudioContext/createMediaStreamTrackSource"><code>AudioContext.createMediaStreamTrackSource()</code></a></dt>
  <dd>
    <p>Creates a <a href="/en-US/docs/Web/API/MediaStreamTrackAudioSourceNode"><code>MediaStreamTrackAudioSourceNode</code></a> associated with a <a href="/en-US/docs/Web/API/MediaStream"><code>MediaStream</code></a> representing an media stream track.</p>
  </dd>
  <dt id="audiocontext.getoutputtimestamp"><a href="/en-US/docs/Web/API/AudioContext/getOutputTimestamp"><code>AudioContext.getOutputTimestamp()</code></a></dt>
  <dd>
    <p>Returns a new <code>AudioTimestamp</code> object containing two audio timestamp values relating to the current audio context.</p>
  </dd>
  <dt id="audiocontext.resume"><a href="/en-US/docs/Web/API/AudioContext/resume"><code>AudioContext.resume()</code></a></dt>
  <dd>
    <p>Resumes the progression of time in an audio context that has previously been suspended/paused.</p>
  </dd>
  <dt id="audiocontext.setsinkid"><a href="/en-US/docs/Web/API/AudioContext/setSinkId"><code>AudioContext.setSinkId()</code></a> <abbr class="icon icon-experimental" title="Experimental. Expect behavior to change in the future.">
    <span class="visually-hidden">Experimental</span>
</abbr> <span class="badge inline secure" title="This feature is available only in secure contexts (HTTPS)">Secure context</span></dt>
  <dd>
    <p>Sets the output audio device for the <code>AudioContext</code>.</p>
  </dd>
  <dt id="audiocontext.suspend"><a href="/en-US/docs/Web/API/AudioContext/suspend"><code>AudioContext.suspend()</code></a></dt>
  <dd>
    <p>Suspends the progression of time in the audio context, temporarily halting audio hardware access and reducing CPU/battery usage in the process.</p>
  </dd>
</dl>
<h2 id="events">Events</h2>
<dl>
  <dt id="sinkchange"><a href="/en-US/docs/Web/API/AudioContext/sinkchange_event" title="sinkchange"><code>sinkchange</code></a> <abbr class="icon icon-experimental" title="Experimental. Expect behavior to change in the future.">
    <span class="visually-hidden">Experimental</span>
</abbr></dt>
  <dd>
    <p>Fired when the output audio device (and therefore, the <a href="/en-US/docs/Web/API/AudioContext/sinkId"><code>AudioContext.sinkId</code></a>) has changed.</p>
  </dd>
</dl>
<h2 id="examples">Examples</h2>
<p>Basic audio context declaration:</p>
<pre class="brush: js">const audioCtx = new AudioContext();

const oscillatorNode = audioCtx.createOscillator();
const gainNode = audioCtx.createGain();
const finish = audioCtx.destination;
// etc.
</pre>
<h2 id="specifications">Specifications</h2><div class="bc-specs" data-bcd-query="api.AudioContext" data-spec-urls="">
  If you're able to see this, something went wrong on this page.
</div>
<h2 id="browser_compatibility">Browser compatibility</h2><div class="bc-data" data-query="api.AudioContext" data-depth="1" data-multiple="false">
  If you're able to see this, something went wrong on this page.
</div>
<h2 id="see_also">See also</h2>
<ul>
  <li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a></li>
  <li><a href="/en-US/docs/Web/API/OfflineAudioContext"><code>OfflineAudioContext</code></a></li>
</ul>
</body></html>