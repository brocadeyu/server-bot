<html><head></head><body>
<p>The <strong><code>AudioWorkletGlobalScope</code></strong> interface of the <a href="/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a> represents a global execution context for user-supplied code, which defines custom <a href="/en-US/docs/Web/API/AudioWorkletProcessor"><code>AudioWorkletProcessor</code></a>-derived classes.</p>
<p>Each <a href="/en-US/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a> has a single <a href="/en-US/docs/Web/API/AudioWorklet"><code>AudioWorklet</code></a> available under the <a href="/en-US/docs/Web/API/BaseAudioContext/audioWorklet" title="audioWorklet"><code>audioWorklet</code></a> property, which runs its code in a single <code>AudioWorkletGlobalScope</code>.</p>
<p>As the global execution context is shared across the current <code>BaseAudioContext</code>, it's possible to define any other variables and perform any actions allowed in worklets — apart from defining <code>AudioWorkletProcessor</code> derived classes.</p><svg viewBox="-1 -1 650 42" preserveAspectRatio="xMinYMin meet">
  <a style="text-decoration: none;" href="/en-US/docs/Web/API/WorkletGlobalScope">
    <rect x="0" y="0" width="144" height="25" fill="#fff" stroke="#D4DDE4" stroke-width="2px"></rect>
    <text x="72" y="16" font-size="10px" fill="#4D4E53" text-anchor="middle">
      WorkletGlobalScope
    </text>
  </a>
  <line x1="144" y1="14" x2="174" y2="14" stroke="#D4DDE4"></line>
  <polyline points="144,14 154,9 154,19 144,14" stroke="#D4DDE4" fill="#fff"></polyline>
  <a style="text-decoration: none;" href="/en-US/docs/Web/API/AudioWorkletGlobalScope" aria-current="page">
    <rect x="174" y="0" width="184" height="25" fill="#F4F7F8" stroke="#D4DDE4" stroke-width="2px"></rect>
    <text x="266" y="16" font-size="10px" fill="#4D4E53" text-anchor="middle">
      AudioWorkletGlobalScope
    </text>
  </a></svg>
<h2 id="instance_properties">Instance properties</h2>
<p><em>This interface also inherits properties defined on its parent interface, <a href="/en-US/docs/Web/API/WorkletGlobalScope"><code>WorkletGlobalScope</code></a>.</em></p>
<dl>
  <dt id="currentframe"><a href="/en-US/docs/Web/API/AudioWorkletGlobalScope/currentFrame" title="currentFrame"><code>currentFrame</code></a> <span class="badge inline readonly" title="This value may not be changed.">Read only </span></dt>
  <dd>
    <p>Returns an integer that represents the ever-increasing current sample-frame of the audio block being processed. It is incremented by 128 (the size of a render quantum) after the processing of each audio block.</p>
  </dd>
  <dt id="currenttime"><a href="/en-US/docs/Web/API/AudioWorkletGlobalScope/currentTime" title="currentTime"><code>currentTime</code></a> <span class="badge inline readonly" title="This value may not be changed.">Read only </span></dt>
  <dd>
    <p>Returns a double that represents the ever-increasing context time of the audio block being processed. It is equal to the <a href="/en-US/docs/Web/API/BaseAudioContext/currentTime" title="currentTime"><code>currentTime</code></a> property of the <a href="/en-US/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a> the worklet belongs to.</p>
  </dd>
  <dt id="samplerate"><a href="/en-US/docs/Web/API/AudioWorkletGlobalScope/sampleRate" title="sampleRate"><code>sampleRate</code></a> <span class="badge inline readonly" title="This value may not be changed.">Read only </span></dt>
  <dd>
    <p>Returns a float that represents the sample rate of the associated <a href="/en-US/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a>.</p>
  </dd>
</dl>
<h2 id="instance_methods">Instance methods</h2>
<p><em>This interface also inherits methods defined on its parent interface, <a href="/en-US/docs/Web/API/WorkletGlobalScope"><code>WorkletGlobalScope</code></a>.</em></p>
<dl>
  <dt id="registerprocessor"><a href="/en-US/docs/Web/API/AudioWorkletGlobalScope/registerProcessor" title="registerProcessor()"><code>registerProcessor()</code></a></dt>
  <dd>
    <p>Registers a class derived from the <a href="/en-US/docs/Web/API/AudioWorkletProcessor"><code>AudioWorkletProcessor</code></a> interface. The class can then be used by creating an <a href="/en-US/docs/Web/API/AudioWorkletNode"><code>AudioWorkletNode</code></a>, providing its registered name.</p>
  </dd>
</dl>
<h2 id="examples">Examples</h2>
<p>In this example we output all global properties into the console in the constructor of a custom <a href="/en-US/docs/Web/API/AudioWorkletProcessor"><code>AudioWorkletProcessor</code></a>.</p>
<p>First we need to define the processor, and register it. Note that this should be done in a separate file.</p>
<pre class="brush: js">// AudioWorkletProcessor defined in : test-processor.js
class TestProcessor extends AudioWorkletProcessor {
  constructor() {
    super();

    // Logs the current sample-frame and time at the moment of instantiation.
    // They are accessible from the AudioWorkletGlobalScope.
    console.log(currentFrame);
    console.log(currentTime);
  }

  // The process method is required - output silence,
  // which the outputs are already filled with.
  process(inputs, outputs, parameters) {
    return true;
  }
}

// Logs the sample rate, that is not going to change ever,
// because it's a read-only property of a BaseAudioContext
// and is set only during its instantiation.
console.log(sampleRate);

// You can declare any variables and use them in your processors
// for example it may be an ArrayBuffer with a wavetable
const usefulVariable = 42;
console.log(usefulVariable);

registerProcessor("test-processor", TestProcessor);
</pre>
<p>Next, in our main scripts file we'll load the processor, create an instance of <a href="/en-US/docs/Web/API/AudioWorkletNode"><code>AudioWorkletNode</code></a> — passing the name of the processor to it — and connect the node to an audio graph. We should see the output of <a href="/en-US/docs/Web/API/console/log_static" title="console.log()"><code>console.log()</code></a> calls in the console:</p>
<pre class="brush: js">const audioContext = new AudioContext();
await audioContext.audioWorklet.addModule("test-processor.js");
const testNode = new AudioWorkletNode(audioContext, "test-processor");
testNode.connect(audioContext.destination);
</pre>
<h2 id="specifications">Specifications</h2><div class="bc-specs" data-bcd-query="api.AudioWorkletGlobalScope" data-spec-urls="">
  If you're able to see this, something went wrong on this page.
</div>
<h2 id="browser_compatibility">Browser compatibility</h2><div class="bc-data" data-query="api.AudioWorkletGlobalScope" data-depth="1" data-multiple="false">
  If you're able to see this, something went wrong on this page.
</div>
<h2 id="see_also">See also</h2>
<ul>
  <li><a href="/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a></li>
  <li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a></li>
  <li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_AudioWorklet">Using AudioWorklet</a></li>
</ul>
</body></html>