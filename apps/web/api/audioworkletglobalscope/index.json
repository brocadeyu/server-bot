{"doc":{"isMarkdown":true,"isTranslated":false,"isActive":true,"flaws":{},"title":"AudioWorkletGlobalScope","mdn_url":"/en-US/docs/Web/API/AudioWorkletGlobalScope","locale":"en-US","native":"English (US)","browserCompat":["api.AudioWorkletGlobalScope"],"baseline":{"baseline":"high","baseline_high_date":"2023-10-26","baseline_low_date":"2021-04-26","support":{"chrome":"66","chrome_android":"66","edge":"79","firefox":"76","firefox_android":"79","safari":"14.1","safari_ios":"14.5"}},"sidebarHTML":"<ol><li class=\"section\"><a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a></li><li class=\"section\"><em><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope\" aria-current=\"page\"><code>AudioWorkletGlobalScope</code></a></em></li><li class=\"toggle\"><details open=\"\"><summary>Instance properties</summary><ol><li><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope/currentFrame\"><code>currentFrame</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope/currentTime\"><code>currentTime</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope/sampleRate\"><code>sampleRate</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Instance methods</summary><ol><li><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope/registerProcessor\"><code>registerProcessor()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Inheritance</summary><ol><li><a href=\"/en-US/docs/Web/API/WorkletGlobalScope\"><code>WorkletGlobalScope</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Related pages for Web Audio API</summary><ol><li><a href=\"/en-US/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioListener\"><code>AudioListener</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioParam\"><code>AudioParam</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a><abbr class=\"icon icon-deprecated\" title=\"Deprecated. Not for use in new websites.\">\n  <span class=\"visually-hidden\">Deprecated</span>\n</abbr></li><li><a href=\"/en-US/docs/Web/API/AudioScheduledSourceNode\"><code>AudioScheduledSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioSinkInfo\"><code>AudioSinkInfo</code></a><abbr class=\"icon icon-experimental\" title=\"Experimental. Expect behavior to change in the future.\">\n    <span class=\"visually-hidden\">Experimental</span>\n</abbr></li><li><a href=\"/en-US/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConstantSourceNode\"><code>ConstantSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/GainNode\"><code>GainNode</code></a></li><li><a href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></li><li><a href=\"/en-US/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code></a></li></ol></details></li></ol>","sidebarMacro":"APIRef","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>The <strong><code>AudioWorkletGlobalScope</code></strong> interface of the <a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a> represents a global execution context for user-supplied code, which defines custom <a href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a>-derived classes.</p>\n<p>Each <a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a> has a single <a href=\"/en-US/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code></a> available under the <a href=\"/en-US/docs/Web/API/BaseAudioContext/audioWorklet\" title=\"audioWorklet\"><code>audioWorklet</code></a> property, which runs its code in a single <code>AudioWorkletGlobalScope</code>.</p>\n<p>As the global execution context is shared across the current <code>BaseAudioContext</code>, it's possible to define any other variables and perform any actions allowed in worklets — apart from defining <code>AudioWorkletProcessor</code> derived classes.</p><svg viewBox=\"-1 -1 650 42\" preserveAspectRatio=\"xMinYMin meet\">\n  <a style=\"text-decoration: none;\" href=\"/en-US/docs/Web/API/WorkletGlobalScope\">\n    <rect x=\"0\" y=\"0\" width=\"144\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"72\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      WorkletGlobalScope\n    </text>\n  </a>\n  <line x1=\"144\" y1=\"14\" x2=\"174\" y2=\"14\" stroke=\"#D4DDE4\"></line>\n  <polyline points=\"144,14 154,9 154,19 144,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope\" aria-current=\"page\">\n    <rect x=\"174\" y=\"0\" width=\"184\" height=\"25\" fill=\"#F4F7F8\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"266\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      AudioWorkletGlobalScope\n    </text>\n  </a></svg>"}},{"type":"prose","value":{"id":"instance_properties","title":"Instance properties","isH3":false,"content":"<p><em>This interface also inherits properties defined on its parent interface, <a href=\"/en-US/docs/Web/API/WorkletGlobalScope\"><code>WorkletGlobalScope</code></a>.</em></p>\n<dl>\n  <dt id=\"currentframe\"><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope/currentFrame\" title=\"currentFrame\"><code>currentFrame</code></a> <span class=\"badge inline readonly\" title=\"This value may not be changed.\">Read only </span></dt>\n  <dd>\n    <p>Returns an integer that represents the ever-increasing current sample-frame of the audio block being processed. It is incremented by 128 (the size of a render quantum) after the processing of each audio block.</p>\n  </dd>\n  <dt id=\"currenttime\"><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope/currentTime\" title=\"currentTime\"><code>currentTime</code></a> <span class=\"badge inline readonly\" title=\"This value may not be changed.\">Read only </span></dt>\n  <dd>\n    <p>Returns a double that represents the ever-increasing context time of the audio block being processed. It is equal to the <a href=\"/en-US/docs/Web/API/BaseAudioContext/currentTime\" title=\"currentTime\"><code>currentTime</code></a> property of the <a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a> the worklet belongs to.</p>\n  </dd>\n  <dt id=\"samplerate\"><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope/sampleRate\" title=\"sampleRate\"><code>sampleRate</code></a> <span class=\"badge inline readonly\" title=\"This value may not be changed.\">Read only </span></dt>\n  <dd>\n    <p>Returns a float that represents the sample rate of the associated <a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a>.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"instance_methods","title":"Instance methods","isH3":false,"content":"<p><em>This interface also inherits methods defined on its parent interface, <a href=\"/en-US/docs/Web/API/WorkletGlobalScope\"><code>WorkletGlobalScope</code></a>.</em></p>\n<dl>\n  <dt id=\"registerprocessor\"><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope/registerProcessor\" title=\"registerProcessor()\"><code>registerProcessor()</code></a></dt>\n  <dd>\n    <p>Registers a class derived from the <a href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a> interface. The class can then be used by creating an <a href=\"/en-US/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code></a>, providing its registered name.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"examples","title":"Examples","isH3":false,"content":"<p>In this example we output all global properties into the console in the constructor of a custom <a href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a>.</p>\n<p>First we need to define the processor, and register it. Note that this should be done in a separate file.</p>\n<div class=\"code-example\"><div class=\"example-header\"><span class=\"language-name\">js</span></div><pre class=\"brush: js notranslate\"><code>// AudioWorkletProcessor defined in : test-processor.js\nclass TestProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n\n    // Logs the current sample-frame and time at the moment of instantiation.\n    // They are accessible from the AudioWorkletGlobalScope.\n    console.log(currentFrame);\n    console.log(currentTime);\n  }\n\n  // The process method is required - output silence,\n  // which the outputs are already filled with.\n  process(inputs, outputs, parameters) {\n    return true;\n  }\n}\n\n// Logs the sample rate, that is not going to change ever,\n// because it's a read-only property of a BaseAudioContext\n// and is set only during its instantiation.\nconsole.log(sampleRate);\n\n// You can declare any variables and use them in your processors\n// for example it may be an ArrayBuffer with a wavetable\nconst usefulVariable = 42;\nconsole.log(usefulVariable);\n\nregisterProcessor(\"test-processor\", TestProcessor);\n</code></pre></div>\n<p>Next, in our main scripts file we'll load the processor, create an instance of <a href=\"/en-US/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code></a> — passing the name of the processor to it — and connect the node to an audio graph. We should see the output of <a href=\"/en-US/docs/Web/API/console/log_static\" title=\"console.log()\"><code>console.log()</code></a> calls in the console:</p>\n<div class=\"code-example\"><div class=\"example-header\"><span class=\"language-name\">js</span></div><pre class=\"brush: js notranslate\"><code>const audioContext = new AudioContext();\nawait audioContext.audioWorklet.addModule(\"test-processor.js\");\nconst testNode = new AudioWorkletNode(audioContext, \"test-processor\");\ntestNode.connect(audioContext.destination);\n</code></pre></div>"}},{"type":"specifications","value":{"title":"Specifications","id":"specifications","isH3":false,"specifications":[{"bcdSpecificationURL":"https://webaudio.github.io/web-audio-api/#AudioWorkletGlobalScope","title":"Web Audio API"}],"query":"api.AudioWorkletGlobalScope"}},{"type":"browser_compatibility","value":{"title":"Browser compatibility","id":"browser_compatibility","isH3":false,"query":"api.AudioWorkletGlobalScope"}},{"type":"prose","value":{"id":"see_also","title":"See also","isH3":false,"content":"<ul>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a></li>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">Using the Web Audio API</a></li>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Using_AudioWorklet\">Using AudioWorklet</a></li>\n</ul>"}}],"toc":[{"text":"Instance properties","id":"instance_properties"},{"text":"Instance methods","id":"instance_methods"},{"text":"Examples","id":"examples"},{"text":"Specifications","id":"specifications"},{"text":"Browser compatibility","id":"browser_compatibility"},{"text":"See also","id":"see_also"}],"summary":"The AudioWorkletGlobalScope interface of the Web Audio API represents a global execution context for user-supplied code, which defines custom AudioWorkletProcessor-derived classes.","popularity":0.0007,"modified":"2020-10-15T22:20:39.790Z","other_translations":[],"pageType":"web-api-interface","source":{"folder":"en-us/web/api/audioworkletglobalscope","github_url":"https://github.com/mdn/content/blob/main/files/en-us/web/api/audioworkletglobalscope/index.md","last_commit_url":"https://github.com/mdn/content/commit/null","filename":"index.md"},"short_title":"AudioWorkletGlobalScope","parents":[{"uri":"/en-US/docs/Web","title":"References"},{"uri":"/en-US/docs/Web/API","title":"Web APIs"},{"uri":"/en-US/docs/Web/API/AudioWorkletGlobalScope","title":"AudioWorkletGlobalScope"}],"pageTitle":"AudioWorkletGlobalScope - Web APIs | MDN","noIndexing":false},"url":"/en-US/docs/Web/API/AudioWorkletGlobalScope"}