{"doc":{"isMarkdown":true,"isTranslated":false,"isActive":true,"flaws":{},"title":"AudioProcessingEvent","mdn_url":"/en-US/docs/Web/API/AudioProcessingEvent","locale":"en-US","native":"English (US)","browserCompat":["api.AudioProcessingEvent"],"sidebarHTML":"<ol><li class=\"section\"><a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a></li><li class=\"section\"><em><a href=\"/en-US/docs/Web/API/AudioProcessingEvent\" aria-current=\"page\"><code>AudioProcessingEvent</code></a><abbr class=\"icon icon-deprecated\" title=\"Deprecated. Not for use in new websites.\">\n  <span class=\"visually-hidden\">Deprecated</span>\n</abbr></em></li><li class=\"toggle\"><details open=\"\"><summary>Constructor</summary><ol><li><a href=\"/en-US/docs/Web/API/AudioProcessingEvent/AudioProcessingEvent\"><code>AudioProcessingEvent()</code></a><abbr class=\"icon icon-deprecated\" title=\"Deprecated. Not for use in new websites.\">\n  <span class=\"visually-hidden\">Deprecated</span>\n</abbr></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Instance properties</summary><ol><li><a href=\"/en-US/docs/Web/API/AudioProcessingEvent/inputBuffer\"><code>inputBuffer</code></a><abbr class=\"icon icon-deprecated\" title=\"Deprecated. Not for use in new websites.\">\n  <span class=\"visually-hidden\">Deprecated</span>\n</abbr></li><li><a href=\"/en-US/docs/Web/API/AudioProcessingEvent/outputBuffer\"><code>outputBuffer</code></a><abbr class=\"icon icon-deprecated\" title=\"Deprecated. Not for use in new websites.\">\n  <span class=\"visually-hidden\">Deprecated</span>\n</abbr></li><li><a href=\"/en-US/docs/Web/API/AudioProcessingEvent/playbackTime\"><code>playbackTime</code></a><abbr class=\"icon icon-deprecated\" title=\"Deprecated. Not for use in new websites.\">\n  <span class=\"visually-hidden\">Deprecated</span>\n</abbr></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Inheritance</summary><ol><li><a href=\"/en-US/docs/Web/API/Event\"><code>Event</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Related pages for Web Audio API</summary><ol><li><a href=\"/en-US/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioListener\"><code>AudioListener</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioParam\"><code>AudioParam</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioScheduledSourceNode\"><code>AudioScheduledSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioSinkInfo\"><code>AudioSinkInfo</code></a><abbr class=\"icon icon-experimental\" title=\"Experimental. Expect behavior to change in the future.\">\n    <span class=\"visually-hidden\">Experimental</span>\n</abbr></li><li><a href=\"/en-US/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope\"><code>AudioWorkletGlobalScope</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConstantSourceNode\"><code>ConstantSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/GainNode\"><code>GainNode</code></a></li><li><a href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></li><li><a href=\"/en-US/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code></a></li></ol></details></li></ol>","sidebarMacro":"APIRef","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<div class=\"notecard deprecated\"><p><strong>Deprecated:</strong> This feature is no longer recommended. Though some browsers might still support it, it may have already been removed from the relevant web standards, may be in the process of being dropped, or may only be kept for compatibility purposes. Avoid using it, and update existing code if possible; see the <a href=\"#browser_compatibility\">compatibility table</a> at the bottom of this page to guide your decision. Be aware that this feature may cease to work at any time.</p></div>\n<p>The <code>AudioProcessingEvent</code> interface of the <a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a> represents events that occur when a <a href=\"/en-US/docs/Web/API/ScriptProcessorNode\"><code>ScriptProcessorNode</code></a> input buffer is ready to be processed.</p>\n<p>An <code>audioprocess</code> event with this interface is fired on a <a href=\"/en-US/docs/Web/API/ScriptProcessorNode\"><code>ScriptProcessorNode</code></a> when audio processing is required. During audio processing, the input buffer is read and processed to produce output audio data, which is then written to the output buffer.</p>\n<div class=\"notecard warning\">\n  <p><strong>Warning:</strong> This feature has been deprecated and should be replaced by an <a href=\"/en-US/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code></a>.</p>\n</div><svg viewBox=\"-1 -1 650 42\" preserveAspectRatio=\"xMinYMin meet\">\n  <a style=\"text-decoration: none;\" href=\"/en-US/docs/Web/API/Event\">\n    <rect x=\"0\" y=\"0\" width=\"75\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"37.5\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      Event\n    </text>\n  </a>\n  <line x1=\"75\" y1=\"14\" x2=\"105\" y2=\"14\" stroke=\"#D4DDE4\"></line>\n  <polyline points=\"75,14 85,9 85,19 75,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" href=\"/en-US/docs/Web/API/AudioProcessingEvent\" aria-current=\"page\">\n    <rect x=\"105\" y=\"0\" width=\"160\" height=\"25\" fill=\"#F4F7F8\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"185\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      AudioProcessingEvent\n    </text>\n  </a></svg>"}},{"type":"prose","value":{"id":"constructor","title":"Constructor","isH3":false,"content":"<dl>\n  <dt id=\"audioprocessingevent\"><a href=\"/en-US/docs/Web/API/AudioProcessingEvent/AudioProcessingEvent\" title=\"AudioProcessingEvent()\"><code>AudioProcessingEvent()</code></a> <abbr class=\"icon icon-deprecated\" title=\"Deprecated. Not for use in new websites.\">\n  <span class=\"visually-hidden\">Deprecated</span>\n</abbr></dt>\n  <dd>\n    <p>Creates a new <code>AudioProcessingEvent</code> object.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"instance_properties","title":"Instance properties","isH3":false,"content":"<p><em>Also implements the properties inherited from its parent, <a href=\"/en-US/docs/Web/API/Event\"><code>Event</code></a></em>.</p>\n<dl>\n  <dt id=\"playbacktime\"><a href=\"/en-US/docs/Web/API/AudioProcessingEvent/playbackTime\" title=\"playbackTime\"><code>playbackTime</code></a> <span class=\"badge inline readonly\" title=\"This value may not be changed.\">Read only </span> <abbr class=\"icon icon-deprecated\" title=\"Deprecated. Not for use in new websites.\">\n  <span class=\"visually-hidden\">Deprecated</span>\n</abbr></dt>\n  <dd>\n    <p>\n      A double representing the time when the audio will be played,\n      as defined by the time of <a href=\"/en-US/docs/Web/API/BaseAudioContext/currentTime\" title=\"AudioContext.currentTime\"><code>AudioContext.currentTime</code></a>.\n    </p>\n  </dd>\n  <dt id=\"inputbuffer\"><a href=\"/en-US/docs/Web/API/AudioProcessingEvent/inputBuffer\" title=\"inputBuffer\"><code>inputBuffer</code></a> <span class=\"badge inline readonly\" title=\"This value may not be changed.\">Read only </span> <abbr class=\"icon icon-deprecated\" title=\"Deprecated. Not for use in new websites.\">\n  <span class=\"visually-hidden\">Deprecated</span>\n</abbr></dt>\n  <dd>\n    <p>\n      An <a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> that is the buffer containing the input audio data to be processed.\n      The number of channels is defined as a parameter <code>numberOfInputChannels</code>,\n      of the factory method <a href=\"/en-US/docs/Web/API/BaseAudioContext/createScriptProcessor\" title=\"AudioContext.createScriptProcessor()\"><code>AudioContext.createScriptProcessor()</code></a>.\n      Note that the returned <code>AudioBuffer</code> is only valid in the scope of the event handler.\n    </p>\n  </dd>\n  <dt id=\"outputbuffer\"><a href=\"/en-US/docs/Web/API/AudioProcessingEvent/outputBuffer\" title=\"outputBuffer\"><code>outputBuffer</code></a> <span class=\"badge inline readonly\" title=\"This value may not be changed.\">Read only </span> <abbr class=\"icon icon-deprecated\" title=\"Deprecated. Not for use in new websites.\">\n  <span class=\"visually-hidden\">Deprecated</span>\n</abbr></dt>\n  <dd>\n    <p>\n      An <a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> that is the buffer where the output audio data should be written.\n      The number of channels is defined as a parameter, <code>numberOfOutputChannels</code>,\n      of the factory method <a href=\"/en-US/docs/Web/API/BaseAudioContext/createScriptProcessor\" title=\"AudioContext.createScriptProcessor()\"><code>AudioContext.createScriptProcessor()</code></a>.\n      Note that the returned <code>AudioBuffer</code> is only valid in the scope of the event handler.\n    </p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"examples","title":"Examples","isH3":false,"content":""}},{"type":"prose","value":{"id":"adding_white_noise_using_a_script_processor","title":"Adding white noise using a script processor","isH3":true,"content":"<p>\n  The following example shows how to use of a <code>ScriptProcessorNode</code> to take a\n  track loaded via <a href=\"/en-US/docs/Web/API/BaseAudioContext/decodeAudioData\" title=\"AudioContext.decodeAudioData()\"><code>AudioContext.decodeAudioData()</code></a>, process it, adding a bit\n  of white noise to each audio sample of the input track (buffer) and play it through the\n  <a href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a>. For each channel and each sample frame, the\n  <code>scriptNode.onaudioprocess</code> function takes the associated\n  <code>audioProcessingEvent</code> and uses it to loop through each channel of the input\n  buffer, and each sample in each channel, and add a small amount of white noise, before\n  setting that result to be the output sample in each case.\n</p>\n<div class=\"notecard note\">\n  <p>\n    <strong>Note:</strong> For a full working example, see our <a href=\"https://mdn.github.io/webaudio-examples/script-processor-node/\" class=\"external\" target=\"_blank\">script-processor-node</a>\n    GitHub repo. (You can also access the <a href=\"https://github.com/mdn/webaudio-examples/tree/main/script-processor-node\" class=\"external\" target=\"_blank\">source code</a>.)\n  </p>\n</div>\n<div class=\"code-example\"><div class=\"example-header\"><span class=\"language-name\">js</span></div><pre class=\"brush: js notranslate\"><code>const myScript = document.querySelector(\"script\");\nconst myPre = document.querySelector(\"pre\");\nconst playButton = document.querySelector(\"button\");\n\n// Create AudioContext and buffer source\nlet audioCtx;\n\nasync function init() {\n  audioCtx = new AudioContext();\n  const source = audioCtx.createBufferSource();\n\n  // Create a ScriptProcessorNode with a bufferSize of 4096 and\n  // a single input and output channel\n  const scriptNode = audioCtx.createScriptProcessor(4096, 1, 1);\n\n  // Load in an audio track using fetch() and decodeAudioData()\n  try {\n    const response = await fetch(\"viper.ogg\");\n    const arrayBuffer = await response.arrayBuffer();\n    source.buffer = await audioCtx.decodeAudioData(arrayBuffer);\n  } catch (err) {\n    console.error(\n      `Unable to fetch the audio file: ${name} Error: ${err.message}`,\n    );\n  }\n\n  // Give the node a function to process audio events\n  scriptNode.addEventListener(\"audioprocess\", (audioProcessingEvent) =&gt; {\n    // The input buffer is the song we loaded earlier\n    let inputBuffer = audioProcessingEvent.inputBuffer;\n\n    // The output buffer contains the samples that will be modified\n    // and played\n    let outputBuffer = audioProcessingEvent.outputBuffer;\n\n    // Loop through the output channels (in this case there is only one)\n    for (let channel = 0; channel &lt; outputBuffer.numberOfChannels; channel++) {\n      let inputData = inputBuffer.getChannelData(channel);\n      let outputData = outputBuffer.getChannelData(channel);\n\n      // Loop through the 4096 samples\n      for (let sample = 0; sample &lt; inputBuffer.length; sample++) {\n        // make output equal to the same as the input\n        outputData[sample] = inputData[sample];\n\n        // add noise to each output sample\n        outputData[sample] += (Math.random() * 2 - 1) * 0.1;\n      }\n    }\n  });\n\n  source.connect(scriptNode);\n  scriptNode.connect(audioCtx.destination);\n  source.start();\n\n  // When the buffer source stops playing, disconnect everything\n  source.addEventListener(\"ended\", () =&gt; {\n    source.disconnect(scriptNode);\n    scriptNode.disconnect(audioCtx.destination);\n  });\n}\n\n// wire up play button\nplayButton.addEventListener(\"click\", () =&gt; {\n  if (!audioCtx) {\n    init();\n  }\n});\n</code></pre></div>"}},{"type":"browser_compatibility","value":{"title":"Browser compatibility","id":"browser_compatibility","isH3":false,"query":"api.AudioProcessingEvent"}},{"type":"prose","value":{"id":"see_also","title":"See also","isH3":false,"content":"<ul>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">Using the Web Audio API</a></li>\n</ul>"}}],"toc":[{"text":"Constructor","id":"constructor"},{"text":"Instance properties","id":"instance_properties"},{"text":"Examples","id":"examples"},{"text":"Browser compatibility","id":"browser_compatibility"},{"text":"See also","id":"see_also"}],"summary":"The AudioProcessingEvent interface of the Web Audio API represents events that occur when a ScriptProcessorNode input buffer is ready to be processed.","popularity":0.0008,"modified":"2020-10-15T21:22:32.385Z","other_translations":[],"pageType":"web-api-interface","source":{"folder":"en-us/web/api/audioprocessingevent","github_url":"https://github.com/mdn/content/blob/main/files/en-us/web/api/audioprocessingevent/index.md","last_commit_url":"https://github.com/mdn/content/commit/null","filename":"index.md"},"short_title":"AudioProcessingEvent","parents":[{"uri":"/en-US/docs/Web","title":"References"},{"uri":"/en-US/docs/Web/API","title":"Web APIs"},{"uri":"/en-US/docs/Web/API/AudioProcessingEvent","title":"AudioProcessingEvent"}],"pageTitle":"AudioProcessingEvent - Web APIs | MDN","noIndexing":false},"url":"/en-US/docs/Web/API/AudioProcessingEvent"}